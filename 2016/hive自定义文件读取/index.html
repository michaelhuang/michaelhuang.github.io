<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Hive自定义文件读取 · learn to love less</title><meta name="description" content="Hive自定义文件读取 - huangzhf"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="http://fonts.useso.com/css?family=Source+Sans+Pro:400,600" type="text/css"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://twitter.com/ZhengfeiHuang" target="_blank" class="nav-list-link">TWITTER</a></li><li class="nav-list-item"><a href="https://github.com/michaelhuang" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">Hive自定义文件读取</h1><div class="post-info">Apr 3, 2016</div><div class="post-content"><blockquote>
<p>考虑这么个场景：某天你leader过来跟你说，我这现在有大量文本文件，大小不一，大的好几十G，小的几百兆；现在想提取出来共有的几个业务字段做分析，但是每种类型的接口文件的字段解析规则还不一样，比如业务字段A，在file1里面在第10字节到18字节之间，在file2中在第8字节到第16字节之间，问你怎么办？</p>
</blockquote>
<a id="more"></a>
<p>如果有现成的hdfs集群，其实这事儿用<code>Hive自定义文件读取</code>这个特性会非常省事儿！</p>
<p><img src="http://michaelhuang.qiniudn.com/hive-serde.jpg" alt="hive-serde"></p>
<p>文件如何读取（<code>inputformat</code>），读取的内容如何解析（<code>serde</code>）</p>
<p>你会发现，你只需要实现几个简单的类，篇头问题即迎刃而解</p>
<h2 id="Inputformat"><a href="#Inputformat" class="headerlink" title="Inputformat"></a>Inputformat</h2><ul>
<li>既然处理文本，当然<code>org.apache.hadoop.mapred.TextInputFormat</code></li>
<li>只需实现接口，把Split传给<code>RecordReader</code>，具体文本切分规则交给<code>RecordReader</code></li>
</ul>
<p><img src="http://michaelhuang.qiniudn.com/hive/XFileInputFormat.png" alt="XFileInputFormat"></p>
<h2 id="RecordReader"><a href="#RecordReader" class="headerlink" title="RecordReader"></a>RecordReader</h2><ul>
<li>主要逻辑在<code>next()</code>中，通过<code>LineRecordReader</code>解析Split，然后生成原始row</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">next</span><span class="params">(LongWritable key, Text value)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="comment">// get current line</span></span><br><span class="line">    <span class="keyword">if</span> (!<span class="keyword">this</span>.reader.next(<span class="keyword">this</span>.lineKey, <span class="keyword">this</span>.lineValue)) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    key.set(key.get() + <span class="number">1</span>);</span><br><span class="line">    lineValue.append(byteOfSplitName, <span class="number">0</span>, byteOfSplitName.length);</span><br><span class="line">    value.set(<span class="keyword">this</span>.lineValue.getBytes());</span><br><span class="line">    <span class="comment">//Text.validateUTF8(value.getBytes());</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="http://michaelhuang.qiniudn.com/hive/XRecordReader.png" alt="XRecordReader"></p>
<h2 id="Serde"><a href="#Serde" class="headerlink" title="Serde"></a>Serde</h2><ul>
<li>负责把每一个原生row根据业务规则解析成多个field，这才产出一条有意义的record</li>
<li><code>initialize()</code>初始化，根据表schema定义，确定好有哪些列，每一列都是什么类型</li>
<li>我们只想读取，所以只需实现<code>deserialize()</code>接口</li>
<li><a href="http://db3.iteye.com/blog/1072778" target="_blank" rel="external">ObjectInspector</a>很精髓！</li>
</ul>
<p><img src="http://michaelhuang.qiniudn.com/hive/XSerDe.png" alt="XSerDe"></p>
<h2 id="Hive-Sql-定义"><a href="#Hive-Sql-定义" class="headerlink" title="Hive Sql 定义"></a>Hive Sql 定义</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">hive -e "<span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> khala_his.dwd_acco_his</span><br><span class="line">(</span><br><span class="line">  c_clientid <span class="keyword">STRING</span>,</span><br><span class="line">  c_custname <span class="keyword">STRING</span>,</span><br><span class="line">  d_datadate <span class="built_in">DATE</span></span><br><span class="line">  ...</span><br><span class="line">)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span> (<span class="keyword">year</span> <span class="built_in">INT</span>, <span class="keyword">month</span> <span class="built_in">INT</span>, <span class="keyword">day</span> <span class="built_in">INT</span>)</span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> SERDE <span class="string">'com.michael.hive.XSerDe'</span></span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span></span><br><span class="line">  INPUTFORMAT <span class="string">'com.michael.hive.XFileInputFormat'</span></span><br><span class="line">  OUTPUTFORMAT <span class="string">'com.michael.hive.XFileOutputFormat'</span></span><br><span class="line">LOCATION <span class="string">'/data/khala/his/dwd_acco_his'</span></span><br></pre></td></tr></table></figure>
<h2 id="Answer"><a href="#Answer" class="headerlink" title="Answer"></a>Answer</h2><p>说到这，还有个关键问题没解决，如何解决同一表schema适配不同文本文件呢？只需两步</p>
<ul>
<li><code>RecordReader</code>把文件名<code>split.getPath().getName()</code>拼到每一个row末尾，相当于加一个虚拟列，用来索引对应row解析规则</li>
<li><code>SerDe</code>解析字段规则时，根据虚拟列获取到解析规则，然后解析即可</li>
</ul>
<div class="tip"><br><code>org.apache.hadoop.io.Text</code>标准UTF8编码，如果你的文本不是UTF8，生成row时要用<code>getBytes()</code>，非<code>toString()</code>；<br>解析类型时候，DECIMAL要用HiveDecimal.create(BigDecimal decimal)，DATE用java.sql.Date()<br></div>

<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/SerDe" target="_blank" rel="external">Apache Hive Serde</a></li>
<li><a href="http://www.dummies.com/how-to/content/defining-table-record-formats-in-hive.html" target="_blank" rel="external">defining table record formats in Hive</a></li>
<li><a href="http://www.coder4.com/archives/4031" target="_blank" rel="external">Hive中的InputFormat、OutputFormat与SerDe</a></li>
</ul>
</div></article></div></section><footer><div class="paginator"><a href="/2016/Spring-test-dbunit/" class="prev">PREV</a><a href="/2016/hive实现拉链存储/" class="next">NEXT</a></div><div class="copyright"><p>© 2015 - 2016 <a href="http://michaelhuang.github.io">huangzhf</a>, <a href="https://github.com/pinggod/hexo-theme-apollo">apollo</a>, <a href="http://hexo.io">hexo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-75326623-1",'auto');ga('send','pageview');</script></body></html>